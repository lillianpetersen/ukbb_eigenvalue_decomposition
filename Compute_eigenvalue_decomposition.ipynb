{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1002\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hail as hl\n",
    "\n",
    "from hail.plot import show\n",
    "from os import path\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.linalg\n",
    "import numpy as np\n",
    "\n",
    "hl.plot.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful command to specify nuimber of partitions:\n",
    "def read_with_partitions(path, n_parts):\n",
    "     mt = hl.read_matrix_table(path)\n",
    "     return hl.read_matrix_table(path, _intervals=mt._calculate_new_partitions(n_parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1pct\n"
     ]
    }
   ],
   "source": [
    "# Set the percent of individuals in the UK Biobank to run the analysis on\n",
    "pct = 1\n",
    "print(str(pct)+\"pct\")\n",
    "# if Refilter = False, use variables that are in storage (same SNPs, same individuals, no re-computations)\n",
    "Refilter = False\n",
    "# If ModifyGRM, use a local genetic_relatedness_matrix function and downweight by LD score\n",
    "ModifyGRM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Specify file names and locations:\n",
    "genomt_file = \"gs://ukb31063/ukb31063.genotype.mt\"\n",
    "\n",
    "withdrawn_file = \"gs://ukb31063/ukb31063.withdrawn_samples.ht\"\n",
    "gwassamples_file =\"gs://ukb31063/ukb31063.neale_gwas_samples.both_sexes.ht\"\n",
    "sampleqc_file = \"gs://ukb31063/ukb31063.sample_qc.tsv.bgz\"\n",
    "snpqc_file = \"gs://ukb-gt/ukb_snp_qc_forHail_chr1to22.txt\"\n",
    "\n",
    "gwasvariants_file = \"gs://ukb31063/ukb31063.neale_gwas_variants.ht\"\n",
    "\n",
    "phenos_file = \"gs://ukb31063/ukb31063.PHESANT_January_2019.both_sexes.tsv.bgz\"\n",
    "assessment_file = \"gs://ukb-gt/ukb_acentre.csv\"\n",
    "covariates_file = \"gs://ukb31063/ukb31063.neale_gwas_covariates.both_sexes.tsv.bgz\"\n",
    "\n",
    "pcvar_file = \"gs://nbaya/sex_linreg/ukb31063.*_phenotypes.both_sexes.reg1.tsv.bgz\"\n",
    "\n",
    "# Saved locally on gs://ukb-gt\n",
    "LDscore_file = \"gs://ukb-gt/LDscores/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ModifyGRM:\n",
    "    # This function computes the GRM of a matrix while downweighting by the LD score of each SNP\n",
    "    # Before calling this function, annotate ukbb as\n",
    "    #   ukbb = ukbb.annotate_rows(LD_score = ld[ukbb.row_key].ld_score)\n",
    "    def genetic_relatedness_matrix(ukbb) -> BlockMatrix:\n",
    "        ukbb = ukbb.annotate_entries(n_alt = ukbb.GT.n_alt_alleles())\n",
    "        ukbb = ukbb.unfilter_entries()\n",
    "        ukbb = ukbb.annotate_rows(AC = agg.sum(ukbb.n_alt),n_called = agg.count_where(hl.is_defined(ukbb.n_alt)))\n",
    "        ukbb = ukbb.filter_rows((ukbb.AC > 0) & (ukbb.AC < 2 * ukbb.n_called))\n",
    "        ukbb = ukbb.annotate_rows(mean_n_alt = ukbb.AC / ukbb.n_called)\n",
    "        ukbb = ukbb.annotate_rows(hwe_scaled_std_dev = hl.sqrt(ukbb.mean_n_alt * (2 - ukbb.mean_n_alt)))\n",
    "        ukbb = ukbb.annotate_rows(normalizer=hl.sqrt(ukbb.mean_n_alt * (2 - ukbb.mean_n_alt) * ukbb.LD_score))\n",
    "        normalized_n_alt = hl.or_else((ukbb.n_alt - ukbb.mean_n_alt) / ukbb.normalizer,0.0)\n",
    "        bm = BlockMatrix.from_entry_expr(normalized_n_alt)\n",
    "        grm = (bm.T @ bm) / (bm.n_rows / 2.0)\n",
    "        return grm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define phenotype and assessment centre classification:\n",
    "withdrawn = hl.read_table(withdrawn_file)\n",
    "gwassamples = hl.read_table(gwassamples_file)\n",
    "ld = hl.read_table(LDscore_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import table of SNPs used in PCA conducted by the UKB:\n",
    "if Refilter:\n",
    "    snpqc = hl.import_table(snpqc_file, delimiter=\" \", impute=True, key='rs_id')\n",
    "    snpqc = snpqc.filter(snpqc.in_PCA == 1, keep=True )  # only keep variants that have in_PCA == 1 (already passed LD pruning)\n",
    "    snpqc = snpqc.annotate(locus=hl.locus(hl.str(snpqc.chromosome), snpqc.position, reference_genome='GRCh37'))\n",
    "    snpqc = snpqc.key_by(snpqc.locus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ukbb genotype MatrixTable and filter\n",
    "if Refilter:\n",
    "    ukbb = hl.read_matrix_table(genomt_file)\n",
    "    ukbb = ukbb.filter_cols(hl.is_defined(gwassamples[ukbb.col_key]), keep=True) #Keep only Neale lab GWAS samples\n",
    "    ukbb = ukbb.filter_cols(hl.is_defined(withdrawn[ukbb.col_key]), keep=False) #withdrawn samples were already removed actually\n",
    "    ukbb = ukbb.sample_cols(pct/100.) # (Lillian) filter number of individuals\n",
    "    ukbb = hl.variant_qc(ukbb)\n",
    "    ukbb = ukbb.filter_rows( (hl.min(ukbb.variant_qc.AF[0], ukbb.variant_qc.AF[1]) > 0.01) & ( ukbb.variant_qc.call_rate > 0.95), keep=True) # MAF > 0.01 and SNP call rate at least 95%\n",
    "    ukbb = hl.sample_qc(ukbb)\n",
    "    ukbb = ukbb.filter_cols( ukbb.sample_qc.call_rate > 0.98, keep=True) # sample missingness must be < 0.02\n",
    "    ukbb = hl.variant_qc(ukbb)\n",
    "    ukbb = ukbb.filter_rows( ukbb.variant_qc.call_rate > 0.98 , keep=True) # SNP missingness must be < 0.02 and hwe pvalue must be < 10^-6\n",
    "    ukbb = ukbb.filter_rows( ukbb.variant_qc.p_value_hwe < 0.0000000001 , keep=False) # SNP missingness must be < 0.02 and hwe pvalue must be < 10^-6\n",
    "    ukbb.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Refilter:\n",
    "    # Save Metadata (write any notes on processing steps, snps, individuals, etc)\n",
    "    metadata = pd.DataFrame({'nindv': [ukbb.count()[0]], 'nsnps': [ukbb.count()[1]], 'processing': ['SNPs from Neale Lab GWAS study']})\n",
    "    metadata.to_csv(\"gs://ukb-gt/\"+str(pct)+\"pct/ukbQC_\"+str(ukbb.count()[0])+\"_x_\"+str(ukbb.count()[1])+\".txt\", index=False)\n",
    "    \n",
    "    # Write intermediate UKB matrix table to file:\n",
    "    ukbQC_file = \"gs://ukb-gt/\"+str(pct)+\"pct/ukbQC_\"+str(ukbb.count()[0])+\"_x_\"+str(ukbb.count()[1])+\".mt\"\n",
    "    ukbb.write(ukbQC_file, overwrite=True)\n",
    "    ukbb.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in UKB and with specified number of partitions:\n",
    "if Refilter:\n",
    "    ukbb = read_with_partitions(ukbQC_file, n_parts=500)\n",
    "    ukbb.count() # counts are for quick checks that everything is correct\n",
    "    \n",
    "    # Filter SNPs to only those found in UKBB PCA\n",
    "    ukbb = ukbb.filter_rows(hl.is_defined(snpqc[ukbb.locus]))\n",
    "    \n",
    "    # Write final UKB matrix table to file:\n",
    "    ukbPCA_file = \"gs://ukb-gt/\"+str(pct)+\"pct/ukbPCA_\"+str(ukbb.count()[0])+\"_x_\"+str(ukbb.count()[1])+\".mt\"\n",
    "    ukbb.write(ukbPCA_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nindvtmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-51fdb1b590a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnindv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3621\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mukbPCA_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gs://ukb-gt/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"pct/ukbPCA_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsnpstmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_x_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnindvtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_meta\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mukbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mukbPCA_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nindvtmp' is not defined"
     ]
    }
   ],
   "source": [
    "# If using old saved data, read it in\n",
    "if not Refilter:\n",
    "    # set number of SNPs and individuals by hand\n",
    "    if pct==10: \n",
    "        nsnps = 575904\n",
    "        nindv = 35946\n",
    "    elif pct==5:\n",
    "        nsnps = 145061\n",
    "        nindv = 17799\n",
    "    elif pct==1:\n",
    "        nsnps = 145089\n",
    "        nindv = 3621\n",
    "    ukbPCA_file = \"gs://ukb-gt/\"+str(pct)+\"pct/ukbPCA_\"+str(nsnps)+\"_x_\"+str(nindv)+\".mt\"\n",
    "    ukbb = hl.import_table(ukbPCA_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ModifyGRM:\n",
    "    # annotate LD scores into UKBB (WARNING: this might be the incorrect LD scores)\n",
    "    ukbb = ukbb.annotate_rows(LD_score = ld[ukbb.row_key].ld_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-14 18:25:15 Hail: INFO: Coerced sorted dataset\n",
      "2021-02-14 18:26:00 Hail: INFO: Wrote all 36 blocks of 145089 x 3621 matrix with block size 4096.\n",
      "2021-02-14 18:26:02 Hail: INFO: Coerced sorted dataset\n",
      "2021-02-14 18:26:09 Hail: INFO: Coerced sorted dataset\n",
      "2021-02-14 18:28:26 Hail: INFO: wrote matrix with 3621 rows and 3621 columns as 1 block of size 4096 to gs://ukb-gt/1pct/grm_145089_x_3621_meta0.mt\n"
     ]
    }
   ],
   "source": [
    "# compute and save the genetic relatedness matrix\n",
    "if ModifyGRM:\n",
    "    grm = genetic_relatedness_matrix(ukbb)\n",
    "else:\n",
    "    grm = hl.genetic_relatedness_matrix(ukbb.GT)\n",
    "grm_file = \"gs://ukb-gt/\"+str(pct)+\"pct/grm_\"+str(ukbb.count()[0])+\"_x_\"+str(ukbb.count()[1])+\".mt\"\n",
    "grm.write(grm_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-14 18:38:01 Hail: INFO: Coerced sorted dataset\n",
      "2021-02-14 18:38:20 Hail: INFO: Coerced sorted dataset\n"
     ]
    }
   ],
   "source": [
    "# Convert the grm to a numpy array and save it\n",
    "nsnps = ukbb.count()[0]\n",
    "nindv = ukbb.count()[1]\n",
    "\n",
    "grm_np = grm.to_numpy()\n",
    "np.save(\"/tmp/grm_\"+str(nsnps)+\"_x_\"+str(nindv)+\".npy\", grm_np)\n",
    "hl.hadoop_copy(\"file:///tmp/grm_\"+str(nsnps)+\"_x_\"+str(nindv)+\".npy\", \"gs://ukb-gt/\"+str(pct)+\"pct/grm_\"+str(nsnps)+\"_x_\"+str(nindv)+\".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-14 18:39:24 Hail: INFO: Coerced sorted dataset\n",
      "2021-02-14 18:39:31 Hail: INFO: Coerced sorted dataset\n"
     ]
    }
   ],
   "source": [
    "# Eigenvalue decomposition\n",
    "eigenvals = np.linalg.eigvalsh(grm_np)\n",
    "np.save(\"/tmp/eigenvals_\"+str(nsnps)+\"_x_\"+str(nindv)+\".npy\", eigenvals)\n",
    "hl.hadoop_copy(\"file:///tmp/eigenvals_\"+str(nsnps)+\"_x_\"+str(nindv)+\".npy\", \"gs://ukb-gt/\"+str(pct)+\"pct/eigenvals_\"+str(nsnps)+\"_x_\"+str(nindv)+\".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nindv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ece4bd8f7c78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Compute Marchenko-Pastur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlmda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnindv\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnsnps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlmdap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlmdam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nindv' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot eigenvalues overlayed with Marchenko-Pastur\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Compute Marchenko-Pastur\n",
    "lmda = nindv / nsnps\n",
    "lmdap = (1 + np.sqrt(lmda))**2\n",
    "lmdam = (1 - np.sqrt(lmda))**2\n",
    "x = np.arange(lmdam, lmdap, 0.001)\n",
    "y = (1/(2*math.pi)) * np.sqrt((lmdap-x)*(x-lmdam)) / (lmda*x)\n",
    "\n",
    "# Plot\n",
    "plt.clf()\n",
    "plt.hist(eigenvals[1:], bins=int(nindv/35), density = True)\n",
    "plt.plot(x, y, '-b', label = 'Marchenko-Pastur Distrubution')\n",
    "plt.title('Eigenvalues for '+str(nindv)+' Individuals ('+str(pct)+'%) and '+str(nsnps)+' SNPs')\n",
    "plt.xlabel('Eigenvalues')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim([0,2.75])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('/tmp/eigenval_dist_'+str(nindv)+'_x_'+str(nsnps)+'.pdf')\n",
    "hl.hadoop_copy('file:///tmp/eigenval_dist_'+str(nindv)+'_x_'+str(nsnps)+'.pdf', 'gs://ukb-gt/'+str(pct)+'pct/eigenval_dist_'+str(nindv)+'_x_'+str(nsnps)+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hail",
   "language": "python",
   "name": "hail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}